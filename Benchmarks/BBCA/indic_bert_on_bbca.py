# -*- coding: utf-8 -*-
"""Indic-Bert on BBCA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19AO-8jfgTpU0cOLrs_9shNuNKAu4riXM
"""


from datasets import load_dataset
from datasets import load_metric

from transformers import Trainer
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from transformers import TrainingArguments

import numpy as np

from functools import partial

def compute_metrics(eval_pred, metric):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

def tokenize_function(examples, tokenizer):
    tz = tokenizer(examples["text"], padding="max_length", truncation=True, max_length=128)
    tz["label"] = [map_keys[x] for x in examples["label"]]
    return tz

#model_name_or_path = 'mrm8488/HindiBERTa'
#model_name_or_path = 'flax-community/roberta-pretraining-hindi'
def evaluate_bbca(model_name_or_path = 'ai4bharat/indic-bert'):
    
    # data prep
    raw_datasets = load_dataset('indic_glue', 'bbca.hi')
    num_labels = len(raw_datasets['train'].unique('label'))
    map_keys = {v:k for k, v in enumerate(raw_datasets['train'].unique('label'))}
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast = False)
    tokenize_function = partial(tokenize_function, tokenizer=tokenizer)
    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
    full_train_dataset = tokenized_datasets["train"]
    full_eval_dataset = tokenized_datasets["test"]

    # model intilization from pretrained weights
    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels)
    training_args = TrainingArguments("test_trainer", evaluation_strategy="epoch")

    # getting the metric for performance computation ready
    metric = load_metric('indic_glue', 'bbca')
    compute_metrics = partial(compute_metrics, metric=metric)
    
    trainer = Trainer(
        model=model, args=training_args, train_dataset=full_train_dataset, eval_dataset=full_eval_dataset, compute_metrics=compute_metrics
    )
    
    # train model
    trainer.train()
    
    # evaluate model
    trainer.evaluate()

if __name__ == "__main__":
    evaluate_bbca()